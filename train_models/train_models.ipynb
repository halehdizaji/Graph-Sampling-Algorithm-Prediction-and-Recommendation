{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738bb100-a2c6-484f-81d2-ac42e2f50f4e",
      "metadata": {
        "id": "738bb100-a2c6-484f-81d2-ac42e2f50f4e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72974c1a-f6bb-4cd5-b93c-ad17ebe7b8d7",
      "metadata": {
        "id": "72974c1a-f6bb-4cd5-b93c-ad17ebe7b8d7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4a8a15-f369-4237-b518-5101159dcfb4",
      "metadata": {
        "id": "9b4a8a15-f369-4237-b518-5101159dcfb4"
      },
      "outputs": [],
      "source": [
        "# zakaj potrebujem ponovno celotni pipeline?\n",
        "# - smo normalizirali target values? ker se lahko drugače nauči za 0.1 in 0.3\n",
        "# - smo ločili 0.1 in 0.3? Ker če ima skoraj vse iste vhodne podatke, je smiselno, da se loči?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583e3589-21fb-4995-9ca1-bf2c3f43e3a5",
      "metadata": {
        "id": "583e3589-21fb-4995-9ca1-bf2c3f43e3a5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def get_graph_features():\n",
        "    return ['node_count/edge_count', 'edge_count/node_count', 'clust_coeff_max', 'clust_coeff_min', 'clust_coeff_avg',\n",
        "            'clust_coeff_var', 'clust_coeff_median', 'degree_min',\n",
        "            'degree_avg', 'degree_var', 'degree_median', 'node_betweenness_centrality_max', 'node_betweenness_centrality_avg',\n",
        "            'node_betweenness_centrality_var', 'node_betweenness_centrality_median',\n",
        "            'eigenvector_centrality_min', 'eigenvector_centrality_var', 'eigenvector_centrality_avg',\n",
        "            'pagerank_centrality_var', 'degrees_spanning_tree_min', 'degrees_spanning_tree_avg', 'degrees_spanning_tree_var',\n",
        "            'graph_density', 'num_connected_components', 'connected_components_size_max',\n",
        "       'connected_components_size_min', 'connected_components_size_mean',\n",
        "       'connected_components_size_var', 'connected_components_size_median',\n",
        "        'pagerank_centrality_min', 'pagerank_centrality_max', 'pagerank_centrality_mean',\n",
        "       'pagerank_centrality_median','degree_assortativity', 'node_nums', 'edge_nums' ]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0410fbe-9df8-46cf-91b5-65ebea6d3242",
      "metadata": {
        "id": "c0410fbe-9df8-46cf-91b5-65ebea6d3242"
      },
      "outputs": [],
      "source": [
        "# features_set_D3: 1\n",
        "\n",
        "def get_graph_features_D3():\n",
        "    # write feature set into file\n",
        "    return ['clust_coeff_calc_time', 'connected_components_calc_time', 'degree_assortativity', 'degree_assortativity_calc_time', 'edge_nums', 'edge_count/node_count',\n",
        "            'eigenvector_centrality_calc_time', 'graph_density', 'clust_coeff_max', 'max_connected_components_size', 'degree_max', 'degrees_spanning_tree_max', 'eigenvector_centrality_max',\n",
        "            'node_betweenness_centrality_max', 'pagerank_centrality_max', 'shortest_path_length_max', 'max_spanning_tree_calc_time', 'clust_coeff_avg', 'mean_connected_components_size', 'degree_avg',\n",
        "            'degrees_spanning_tree_avg', 'eigenvector_centrality_avg', 'node_betweenness_centrality_avg', 'shortest_path_length_avg', 'clust_coeff_median', 'median_connected_components_size',\n",
        "            'degree_median', 'degrees_spanning_tree_median', 'eigenvector_centrality_median', 'node_betweenness_centrality_median', 'pagerank_centrality_median', 'clust_coeff_min',\n",
        "            'min_connected_components_size', 'degree_min', 'degrees_spanning_tree_min', 'eigenvector_centrality_min', 'node_betweenness_centrality_min', 'pagerank_centrality_min',\n",
        "            'shortest_path_length_min', 'node_count/edge_count', 'num_connected_components', 'pagerank_centrality_calc_time', 'clust_coeff_var', 'var_connected_components_size', 'degree_var',\n",
        "            'degrees_spanning_tree_var', 'eigenvector_centrality_var', 'node_betweenness_centrality_var', 'pagerank_centrality_var', 'shortest_path_length_var']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63511e1a-27c7-48c9-9767-928ff1bdb776",
      "metadata": {
        "id": "63511e1a-27c7-48c9-9767-928ff1bdb776"
      },
      "outputs": [],
      "source": [
        "# features_set_C2D2: 1\n",
        "\n",
        "def get_graph_features_C2D2():\n",
        "    # write feature set into file\n",
        "    return ['clust_coeff_calc_time', 'connected_components_calc_time', 'degree_assortativity', 'degree_assortativity_calc_time', 'eigenvector_centrality_calc_time',\n",
        "            'max_connected_components_size', 'eigenvector_centrality_max', 'node_betweenness_centrality_max', 'pagerank_centrality_max', 'max_spanning_tree_calc_time',\n",
        "            'clust_coeff_avg', 'mean_connected_components_size', 'degrees_spanning_tree_avg', 'eigenvector_centrality_avg', 'node_betweenness_centrality_avg', 'pagerank_centrality_avg',\n",
        "            'shortest_path_length_avg', 'clust_coeff_median', 'median_connected_components_size', 'eigenvector_centrality_median', 'node_betweenness_centrality_median', 'pagerank_centrality_median',\n",
        "            'clust_coeff_min', 'min_connected_components_size', 'node_betweenness_centrality_min', 'pagerank_centrality_min', 'shortest_path_length_min', 'node_nums', 'pagerank_centrality_calc_time',\n",
        "            'clust_coeff_var', 'degree_var', 'node_betweenness_centrality_var', 'pagerank_centrality_var']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6ef9a52-c042-494c-8f52-b82d591464ca",
      "metadata": {
        "id": "b6ef9a52-c042-494c-8f52-b82d591464ca"
      },
      "outputs": [],
      "source": [
        "# features_set_run_time: 1\n",
        "# to correct\n",
        "def get_graph_features_run_time():\n",
        "    # write feature set into file\n",
        "    return ['clust_coeff_calc_time', 'connected_components_calc_time', 'degree_assortativity_calc_time', 'edge_nums', 'eigenvector_centrality_calc_time', 'graph_density',\n",
        "            'max_connected_components_size', 'max_spanning_tree_calc_time', 'mean_connected_components_size', 'eigenvector_centrality_avg', 'node_betweenness_centrality_avg',\n",
        "            'pagerank_centrality_avg', 'median_connected_components_size', 'eigenvector_centrality_median', 'node_betweenness_centrality_median', 'pagerank_centrality_median',\n",
        "            'min_connected_components_size', 'pagerank_centrality_min', 'shortest_path_length_min', 'node_nums', 'pagerank_centrality_calc_time', 'run_time var', 'sampling_percent', 'pagerank_centrality_var']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24166368-c93c-4044-aeaf-3dc4201d885c",
      "metadata": {
        "id": "24166368-c93c-4044-aeaf-3dc4201d885c"
      },
      "outputs": [],
      "source": [
        "# features_set_run_time: 1\n",
        "# to correct\n",
        "def get_graph_features_HPD2_LCC():\n",
        "    # write feature set into file\n",
        "\n",
        "    return ['connected_components_calc_time', 'degrees_spanning_tree_max', 'pagerank_centrality_avg', 'degrees_spanning_tree_median', 'clust_coeff_min', 'shortest_path_length_min',\n",
        "            'node_nums', 'var_connected_components_size', 'shortest_path_length_var']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d690a739-2b51-410c-8b7c-741cdabf6020",
      "metadata": {
        "id": "d690a739-2b51-410c-8b7c-741cdabf6020"
      },
      "outputs": [],
      "source": [
        "# features_set_run_time: 1\n",
        "# to correct\n",
        "def get_graph_features_HPD2():\n",
        "    # write feature set into file\n",
        "    return ['clust_coeff_calc_time', 'graph_density', 'max_connected_components_size', 'degree_max', 'degrees_spanning_tree_max', 'mean_connected_components_size', 'pagerank_centrality_avg',\n",
        "            'degrees_spanning_tree_median', 'node_betweenness_centrality_median', 'shortest_path_length_min', 'node_nums', 'num_connected_components', 'pagerank_centrality_calc_time',\n",
        "            'var_connected_components_size', 'degree_var', 'degrees_spanning_tree_var']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e7359d9-75db-4af1-8a6a-caf01cd5b394",
      "metadata": {
        "id": "5e7359d9-75db-4af1-8a6a-caf01cd5b394"
      },
      "outputs": [],
      "source": [
        "def get_sampler_features():\n",
        "    return ['sampling_percent', 'forest fire', 'random degree node', 'random edge', 'random jump', 'random node', 'random node edge', 'snowball', 'frontier', 'rank degree', 'induced random edge', 'metropolis hastings random walk', 'expansion', 'sampler_type_node_based', 'sampler_type_edge_based', 'sampler_type_traversal_based']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47749cec-e08f-41c3-b8be-aefe347b97c7",
      "metadata": {
        "id": "47749cec-e08f-41c3-b8be-aefe347b97c7"
      },
      "outputs": [],
      "source": [
        "def get_execution_time_features():\n",
        "    return ['clust_coeff_calc_time', 'node_edge_betweenness_centrality_calc_time',\n",
        "       'connected_components_calc_time', 'pagerank_centrality_calc_time', 'eigenvector_centrality_calc_time',\n",
        "       'max_spanning_tree_calc_time', 'degree_assortativity_calc_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58243069-fdfe-4164-859b-03701147a4b1",
      "metadata": {
        "id": "58243069-fdfe-4164-859b-03701147a4b1"
      },
      "outputs": [],
      "source": [
        "def get_features(metric):\n",
        "    if metric == 'D3':\n",
        "        return get_graph_features_D3()+get_sampler_features()\n",
        "    if metric == 'C2D2':\n",
        "        return get_graph_features_C2D2()+get_sampler_features()\n",
        "    if metric == 'HPD2':\n",
        "        return get_graph_features_HPD2()+get_sampler_features()\n",
        "    if metric == 'HPD2_LCC':\n",
        "        return get_graph_features_HPD2_LCC()+get_sampler_features()\n",
        "    if metric == 'run_time':\n",
        "        return get_graph_features_run_time()+get_sampler_features()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9673b828-f808-4de8-a28e-af8199ae7293",
      "metadata": {
        "id": "9673b828-f808-4de8-a28e-af8199ae7293"
      },
      "outputs": [],
      "source": [
        "def get_model_and_params(algorithm):\n",
        "    if algorithm=='RF':\n",
        "        model = RandomForestRegressor(random_state=0)\n",
        "        params = {'bootstrap':[True], 'max_depth':[None, 90, 100, 110], 'max_features': [2, 3], 'min_samples_leaf': [2, 3, 4, 5],\n",
        "                  'min_samples_split': [8, 10, 12], 'n_estimators': [100, 200, 300, 400]}\n",
        "    if algorithm=='MLP':\n",
        "        model = MLPRegressor(random_state=1, max_iter=500)\n",
        "        params = {'hidden_layer_sizes': [(30), (50), (100), (30,30), (50,50), (100,100)],\n",
        "                      'activation': ['tanh', 'relu'], 'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.05],\n",
        "                      'learning_rate': ['constant', 'adaptive'], 'shuffle': [True], 'early_stopping': [True]}\n",
        "    if algorithm=='kNN':\n",
        "        model = KNeighborsRegressor()\n",
        "        params = {'n_neighbors': [4, 5, 10, 15], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "    return model, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1f1c92-f8a0-4724-9a5e-d1bc5c08c89e",
      "metadata": {
        "id": "8c1f1c92-f8a0-4724-9a5e-d1bc5c08c89e"
      },
      "outputs": [],
      "source": [
        "def get_features_set_num(target):\n",
        "    if target == 'D3':\n",
        "        return features_set_D3\n",
        "    elif target == 'C2D2':\n",
        "        return features_set_C2D2\n",
        "    elif target == 'HPD2':\n",
        "        return features_set_HPD2\n",
        "    elif target == 'run_time':\n",
        "        return features_set_run_time\n",
        "    elif target == 'HPD2_LCC':\n",
        "        return features_set_HPD2_LCC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeaf4a23-8d5a-43d3-b32c-dea6ebf5e795",
      "metadata": {
        "id": "aeaf4a23-8d5a-43d3-b32c-dea6ebf5e795"
      },
      "outputs": [],
      "source": [
        "def train_model(train_set, features, algorithm, target):\n",
        "    model, params = get_model_and_params(algorithm)\n",
        "    optimized = GridSearchCV(model, params)\n",
        "    optimized.fit(train_set[features], train_set[[target]])\n",
        "    return optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aea8633-b6d8-4a57-ab3e-2e5209c10f46",
      "metadata": {
        "id": "8aea8633-b6d8-4a57-ab3e-2e5209c10f46"
      },
      "outputs": [],
      "source": [
        "def export_result(df, columns, target_col, pred_col, synthetic, metric, algorithm, model_num, res_version):\n",
        "    result = df[columns].copy(deep=True)\n",
        "    result.rename(columns={target_col: 'target', pred_col: 'pred'}, inplace=True)\n",
        "    result.to_csv(root_folder + 'results/model_' + model_num + '/{}-{}-{}-feature-set-{}{}.csv'.format(synthetic, metric, algorithm, feature_set_num, res_version), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "110b9e35-ef50-44b5-aea9-28960bbcd067",
      "metadata": {
        "id": "110b9e35-ef50-44b5-aea9-28960bbcd067"
      },
      "outputs": [],
      "source": [
        "def export_features(feature_list, metric, algorithm, model_num, root_folder):\n",
        "    with open(root_folder + '/results/model_' + model_num + '/features-{}-{}-feature-set-{}.csv'.format(metric, algorithm, feature_set_num), 'w') as the_file:\n",
        "        the_file.write(','.join(feature_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8112e73-0861-4eb9-977f-94e025572483",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8112e73-0861-4eb9-977f-94e025572483",
        "outputId": "a82fb42c-9895-45a3-c265-12372bec8c51"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training kNN for run_time\n",
            "Training RF for run_time\n",
            "Training MLP for run_time\n"
          ]
        }
      ],
      "source": [
        "# train and test models\n",
        "\n",
        "import pickle as pickle\n",
        "model_params = {}\n",
        "data_type = 'syn'\n",
        "features_set_C2D2 = '2'\n",
        "features_set_D3 = '2'\n",
        "features_set_HPD2 = '2'\n",
        "features_set_HPD2_LCC = '2'\n",
        "features_set_run_time = '2'\n",
        "model_num = '2'\n",
        "res_version = ''\n",
        "root_folder = 'drive/MyDrive/Research/Projects/Graph_Sampling_Prediction/notebooks-export/'\n",
        "data_folder = 'data/model_' + model_num\n",
        "#result_dir = root_folder + '/results/' + result_folder_name\n",
        "#if not os.path.exists(result_dir):\n",
        "#    os.makedirs(result_dir)\n",
        "\n",
        "for target in ['run_time']:\n",
        "#for target in ['HPD2_LCC']:\n",
        "    df = pd.read_csv(root_folder + data_folder + '/{}.csv'.format(target))\n",
        "    feature_set_num = get_features_set_num(target)\n",
        "    train_set = df[(df['partition']=='train')].reset_index()\n",
        "    test_set_synth_medium = df[(df['partition']=='test') & (df['synthetic']=='synthetic_medium')].reset_index()\n",
        "    test_set_synth_large = df[(df['partition']=='test') & (df['synthetic']=='synthetic_large')].reset_index()\n",
        "    test_set_rw_medium = df[(df['partition']=='test') & (df['synthetic']=='realworld_medium')].reset_index()\n",
        "    test_set_rw_large = df[(df['partition']=='test') & (df['synthetic']=='realworld_large')].reset_index()\n",
        "\n",
        "    features = get_features(target)\n",
        "    pred_colname = '{}_pred'.format(target)\n",
        "    result_cols = ['graph_ID', 'node_nums', 'graph_density', 'sampling_percent', 'sampling algorithm', target, pred_colname]\n",
        "    #result_cols = ['graph type', 'node_nums', 'graph_density', 'graph param', 'sample_rates', 'sampling_algorithm', target, pred_colname]\n",
        "    model_params[target]={}\n",
        "    #for algorithm in ['RF']:\n",
        "    for algorithm in ['kNN','RF', 'MLP']: #['RF', 'kNN', 'MLP', 'LR', 'NB']\n",
        "        print('Training {} for {}'.format(algorithm, target))\n",
        "        #print(train_set[features])\n",
        "        #print(train_set[target])\n",
        "        model = train_model(train_set, features, algorithm, target)\n",
        "        filename = root_folder + '/out/models/{}-{}-{}-feature-set-{}.pickle'.format(model_num, algorithm, target, feature_set_num)\n",
        "        pickle.dump(model, open(filename, 'wb'))\n",
        "        model_params[target][algorithm]=model.best_params_\n",
        "\n",
        "        test_set_synth_medium[pred_colname] = model.predict(test_set_synth_medium[features])\n",
        "        test_set_synth_large[pred_colname] = model.predict(test_set_synth_large[features])\n",
        "        test_set_rw_medium[pred_colname] = model.predict(test_set_rw_medium[features])\n",
        "        test_set_rw_large[pred_colname] = model.predict(test_set_rw_large[features])\n",
        "\n",
        "        export_result(test_set_synth_medium, result_cols, target, pred_colname, 'synthetic_medium', target, algorithm, model_num,res_version)\n",
        "        export_result(test_set_rw_medium, result_cols, target, pred_colname, 'real_world_medium', target, algorithm, model_num, res_version)\n",
        "        export_result(test_set_synth_large, result_cols, target, pred_colname, 'synthetic_large', target, algorithm, model_num, res_version)\n",
        "        export_result(test_set_rw_large, result_cols, target, pred_colname, 'real_world_large', target, algorithm, model_num, res_version)\n",
        "        export_features(features, target, algorithm, model_num, root_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hIB8chGq6446",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIB8chGq6446",
        "outputId": "728cff4d-be4a-414b-b4dd-3424182b4e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dfa3126-180a-4d86-a020-6341999b78ef",
      "metadata": {
        "id": "1dfa3126-180a-4d86-a020-6341999b78ef"
      },
      "outputs": [],
      "source": [
        "def data_quality_check(df):\n",
        "    print(df.columns[df.isna().any()].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1dcc500-7e26-4f5a-984e-31d417220d62",
      "metadata": {
        "id": "a1dcc500-7e26-4f5a-984e-31d417220d62",
        "outputId": "13d626ba-cb6d-460f-cf3c-f7d9c8b1905c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing kNN for D3\n",
            "Testing RF for D3\n",
            "Testing MLP for D3\n",
            "Testing kNN for C2D2\n",
            "Testing RF for C2D2\n",
            "Testing MLP for C2D2\n",
            "Testing kNN for HPD2_LCC\n",
            "Testing RF for HPD2_LCC\n",
            "Testing MLP for HPD2_LCC\n",
            "Testing kNN for HPD2\n",
            "Testing RF for HPD2\n",
            "Testing MLP for HPD2\n"
          ]
        }
      ],
      "source": [
        "# test models\n",
        "\n",
        "import pickle as pickle\n",
        "model_params = {}\n",
        "features_set_C2D2 = '2'\n",
        "features_set_D3 = '2'\n",
        "features_set_HPD2 = '2'\n",
        "features_set_HPD2_LCC = '2'\n",
        "features_set_run_time = '2'\n",
        "model_num = '2'\n",
        "res_version = '_v4'\n",
        "root_folder = 'drive/MyDrive/Research/Projects/Graph_Sampling_Prediction/notebooks-export/'\n",
        "data_folder = 'data/model_' + model_num\n",
        "#result_dir = root_folder + '/results/' + result_folder_name\n",
        "#if not os.path.exists(result_dir):\n",
        "#    os.makedirs(result_dir)\n",
        "\n",
        "for target in ['D3', 'C2D2','HPD2_LCC', 'HPD2']:\n",
        "#for target in ['HPD2_LCC']:\n",
        "    df = pd.read_csv(root_folder + data_folder + '/{}{}.csv'.format(target, res_version))\n",
        "    feature_set_num = get_features_set_num(target)\n",
        "    #train_set = df[(df['partition']=='train')].reset_index()\n",
        "    test_set_synth_medium = df[(df['partition']=='test') & (df['synthetic']=='synthetic_medium')].reset_index()\n",
        "    test_set_synth_large = df[(df['partition']=='test') & (df['synthetic']=='synthetic_large')].reset_index()\n",
        "    test_set_rw_medium = df[(df['partition']=='test') & (df['synthetic']=='realworld_medium')].reset_index()\n",
        "    test_set_rw_large = df[(df['partition']=='test') & (df['synthetic']=='realworld_large')].reset_index()\n",
        "\n",
        "    features = get_features(target)\n",
        "    pred_colname = '{}_pred'.format(target)\n",
        "    result_cols = ['graph_ID', 'node_nums', 'graph_density', 'sampling_percent', 'sampling algorithm', target, pred_colname]\n",
        "    #result_cols = ['graph type', 'node_nums', 'graph_density', 'graph param', 'sample_rates', 'sampling_algorithm', target, pred_colname]\n",
        "    model_params[target]={}\n",
        "    #for algorithm in ['RF']:\n",
        "    for algorithm in ['kNN','RF', 'MLP']: #['RF', 'kNN', 'MLP', 'LR', 'NB']\n",
        "        print('Testing {} for {}'.format(algorithm, target))\n",
        "        #print(train_set[features])\n",
        "        #print(train_set[target])\n",
        "        filename = root_folder + '/out/models/{}-{}-{}-feature-set-{}.pickle'.format(model_num, algorithm, target, feature_set_num)\n",
        "        model = pickle.load(open(filename, 'rb'))\n",
        "        model_params[target][algorithm]=model.best_params_\n",
        "\n",
        "        #test_set_synth_medium[pred_colname] = model.predict(test_set_synth_medium[features])\n",
        "        #test_set_synth_large[pred_colname] = model.predict(test_set_synth_large[features])\n",
        "        test_set_rw_medium[pred_colname] = model.predict(test_set_rw_medium[features])\n",
        "        test_set_rw_large[pred_colname] = model.predict(test_set_rw_large[features])\n",
        "\n",
        "        #export_result(test_set_synth_medium, result_cols, target, pred_colname, 'synthetic_medium', target, algorithm, model_num, res_version)\n",
        "        export_result(test_set_rw_medium, result_cols, target, pred_colname, 'real_world_medium', target, algorithm, model_num, res_version)\n",
        "        #export_result(test_set_synth_large, result_cols, target, pred_colname, 'synthetic_large', target, algorithm, model_num, res_version)\n",
        "        export_result(test_set_rw_large, result_cols, target, pred_colname, 'real_world_large', target, algorithm, model_num, res_version)\n",
        "        #export_features(features, target, algorithm, model_num, root_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf981479-3e75-4128-a365-0f9c207d35a6",
      "metadata": {
        "id": "cf981479-3e75-4128-a365-0f9c207d35a6"
      },
      "outputs": [],
      "source": [
        "# Best model for RF@runtime: {'bootstrap': True, 'max_depth': None, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 100}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('out/models/model_params-D3.json', 'w') as fp:\n",
        "    json.dump(model_params, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09151e30-dfe6-4017-a0be-5fd906f06245",
      "metadata": {
        "id": "09151e30-dfe6-4017-a0be-5fd906f06245"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}